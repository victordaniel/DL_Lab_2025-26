PS E:\Reserach\DL_Lab> & E:/Reserach/DL_Lab/venv/Scripts/Activate.ps1
(venv) PS E:\Reserach\DL_Lab> & E:/Reserach/DL_Lab/venv/Scripts/python.exe e:/Reserach/DL_Lab/cifar_mlp.py
2025-07-23 00:51:40.008324: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical 
results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-07-23 00:51:46.194821: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical 
results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
E:\Reserach\DL_Lab\venv\Lib\site-packages\keras\src\layers\reshaping\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` 
argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(**kwargs)
2025-07-23 00:52:07.727403: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU 
instructions in performance-critical operations.
To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Epoch 1/10
782/782 ━━━━━━━━━━━━━━━━━━━━ 50s 48ms/step - accuracy: 0.1964 - loss: 100.6478 - val_accuracy: 0.2632 - val_loss: 2.2454
Epoch 2/10
782/782 ━━━━━━━━━━━━━━━━━━━━ 40s 51ms/step - accuracy: 0.3304 - loss: 1.9416 - val_accuracy: 0.3329 - val_loss: 1.8473
Epoch 3/10
782/782 ━━━━━━━━━━━━━━━━━━━━ 42s 53ms/step - accuracy: 0.3539 - loss: 1.8260 - val_accuracy: 0.3900 - val_loss: 1.7367
Epoch 4/10
782/782 ━━━━━━━━━━━━━━━━━━━━ 78s 48ms/step - accuracy: 0.3787 - loss: 1.7569 - val_accuracy: 0.3338 - val_loss: 1.9315
Epoch 5/10
782/782 ━━━━━━━━━━━━━━━━━━━━ 36s 46ms/step - accuracy: 0.3762 - loss: 1.7683 - val_accuracy: 0.3800 - val_loss: 1.7207
Epoch 6/10
782/782 ━━━━━━━━━━━━━━━━━━━━ 36s 46ms/step - accuracy: 0.3848 - loss: 1.7341 - val_accuracy: 0.3907 - val_loss: 1.7340
Epoch 7/10
782/782 ━━━━━━━━━━━━━━━━━━━━ 41s 46ms/step - accuracy: 0.3966 - loss: 1.6923 - val_accuracy: 0.3849 - val_loss: 1.7023
Epoch 8/10
782/782 ━━━━━━━━━━━━━━━━━━━━ 36s 46ms/step - accuracy: 0.3983 - loss: 1.6780 - val_accuracy: 0.4077 - val_loss: 1.6964
Epoch 9/10
782/782 ━━━━━━━━━━━━━━━━━━━━ 36s 46ms/step - accuracy: 0.4058 - loss: 1.6619 - val_accuracy: 0.4295 - val_loss: 1.6193
Epoch 10/10
782/782 ━━━━━━━━━━━━━━━━━━━━ 38s 48ms/step - accuracy: 0.4131 - loss: 1.6413 - val_accuracy: 0.3918 - val_loss: 1.6860
313/313 ━━━━━━━━━━━━━━━━━━━━ 2s 7ms/step - accuracy: 0.3913 - loss: 1.6813  
accuracy:0.3917999863624573
Traceback (most recent call last):
    plt.show()
  File "E:\Reserach\DL_Lab\venv\Lib\site-packages\matplotlib\pyplot.py", line 614, in show
    return _get_backend_mod().show(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Reserach\DL_Lab\venv\Lib\site-packages\matplotlib\backend_bases.py", line 3548, in show
    cls.mainloop()
  File "E:\Reserach\DL_Lab\venv\Lib\site-packages\matplotlib\backends\_backend_tk.py", line 544, in start_main_loop
    first_manager.window.mainloop()
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\tkinter\__init__.py", line 1504, in mainloop
    self.tk.mainloop(n)
KeyboardInterrupt
(venv) PS E:\Reserach\DL_Lab> & E:/Reserach/DL_Lab/venv/Scripts/python.exe e:/Reserach/DL_Lab/cifar_mlp.py
2025-07-23 01:01:37.628812: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical 
results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-07-23 01:01:38.978732: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical 
results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
E:\Reserach\DL_Lab\venv\Lib\site-packages\keras\src\layers\reshaping\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` 
argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(**kwargs)
2025-07-23 01:01:46.132817: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU 
instructions in performance-critical operations.
To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Epoch 1/10
782/782 ━━━━━━━━━━━━━━━━━━━━ 47s 58ms/step - accuracy: 0.1984 - loss: 70.0679 - val_accuracy: 0.2978 - val_loss: 2.0776
Epoch 2/10
782/782 ━━━━━━━━━━━━━━━━━━━━ 50s 64ms/step - accuracy: 0.3239 - loss: 1.9572 - val_accuracy: 0.3767 - val_loss: 1.7522
Epoch 3/10
782/782 ━━━━━━━━━━━━━━━━━━━━ 71s 49ms/step - accuracy: 0.3556 - loss: 1.8271 - val_accuracy: 0.3581 - val_loss: 1.7891
Epoch 4/10
782/782 ━━━━━━━━━━━━━━━━━━━━ 41s 52ms/step - accuracy: 0.3652 - loss: 1.7898 - val_accuracy: 0.3646 - val_loss: 1.7766
Epoch 5/10
782/782 ━━━━━━━━━━━━━━━━━━━━ 40s 51ms/step - accuracy: 0.3746 - loss: 1.7625 - val_accuracy: 0.3561 - val_loss: 1.8253
Epoch 6/10
782/782 ━━━━━━━━━━━━━━━━━━━━ 40s 51ms/step - accuracy: 0.3769 - loss: 1.7522 - val_accuracy: 0.3879 - val_loss: 1.7203
Epoch 7/10
782/782 ━━━━━━━━━━━━━━━━━━━━ 41s 52ms/step - accuracy: 0.3856 - loss: 1.7164 - val_accuracy: 0.4048 - val_loss: 1.6870
Epoch 8/10
782/782 ━━━━━━━━━━━━━━━━━━━━ 43s 55ms/step - accuracy: 0.3934 - loss: 1.6953 - val_accuracy: 0.3774 - val_loss: 1.7255
Epoch 9/10
Epoch 10/10
782/782 ━━━━━━━━━━━━━━━━━━━━ 46s 59ms/step - accuracy: 0.4108 - loss: 1.6361 - val_accuracy: 0.3986 - val_loss: 1.6674
313/313 ━━━━━━━━━━━━━━━━━━━━ 3s 8ms/step - accuracy: 0.3988 - loss: 1.6693
accuracy:0.3986000120639801
Traceback (most recent call last):
  File "e:\Reserach\DL_Lab\cifar_mlp.py", line 38, in <module>
    plt.xlabel("epochs")
    ^^^^^^^^^^^^^
  File "E:\Reserach\DL_Lab\venv\Lib\site-packages\matplotlib\pyplot.py", line 1251, in savefig
    res = fig.savefig(*args, **kwargs)  # type: ignore[func-returns-value]
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Figure.savefig() missing 1 required positional argument: 'fname'
(venv) PS E:\Reserach\DL_Lab> & E:/Reserach/DL_Lab/venv/Scripts/python.exe e:/Reserach/DL_Lab/cifar_updated.py
2025-07-23 01:19:58.439819: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical 
results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-07-23 01:20:00.005521: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical 
results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
E:\Reserach\DL_Lab\venv\Lib\site-packages\keras\src\layers\convolutional\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.  
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2025-07-23 01:20:08.189166: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU 
instructions in performance-critical operations.
To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
E:\Reserach\DL_Lab\venv\Lib\site-packages\keras\src\trainers\data_adapters\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class 
 not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
Traceback (most recent call last):
  File "e:\Reserach\DL_Lab\cifar_updated.py", line 66, in <module>
    history = model.fit(datagen.flow(x_train, y_train, batch_size=64),
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Reserach\DL_Lab\venv\Lib\site-packages\keras\src\utils\traceback_utils.py", line 122, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "E:\Reserach\DL_Lab\venv\Lib\site-packages\keras\src\utils\module_utils.py", line 29, in initialize
    raise ImportError(self.import_error_msg)
ImportError: This requires the scipy module. You can install it via `pip install scipy`
(venv) PS E:\Reserach\DL_Lab> pip install scipy^C
(venv) PS E:\Reserach\DL_Lab> & E:/Reserach/DL_Lab/venv/Scripts/python.exe e:/Reserach/DL_Lab/cifar_updated.py
2025-07-23 01:21:10.188469: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical 
results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-07-23 01:21:12.490236: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical 
results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
E:\Reserach\DL_Lab\venv\Lib\site-packages\keras\src\layers\convolutional\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.  
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2025-07-23 01:21:20.443751: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU 
instructions in performance-critical operations.
To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
Traceback (most recent call last):
  File "e:\Reserach\DL_Lab\cifar_updated.py", line 66, in <module>
    history = model.fit(datagen.flow(x_train, y_train, batch_size=64),
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    raise e.with_traceback(filtered_tb) from None
  File "E:\Reserach\DL_Lab\venv\Lib\site-packages\keras\src\utils\module_utils.py", line 29, in initialize
    raise ImportError(self.import_error_msg)
ImportError: This requires the scipy module. You can install it via `pip install scipy`
(venv) PS E:\Reserach\DL_Lab> pip install scipy
Collecting scipy
  Downloading scipy-1.16.0-cp311-cp311-win_amd64.whl.metadata (60 kB)
Requirement already satisfied: numpy<2.6,>=1.25.2 in e:\reserach\dl_lab\venv\lib\site-packages (from scipy) (2.1.3)
Downloading scipy-1.16.0-cp311-cp311-win_amd64.whl (38.6 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 38.6/38.6 MB 3.5 MB/s eta 0:00:00
Installing collected packages: scipy
Successfully installed scipy-1.16.0
(venv) PS E:\Reserach\DL_Lab> & E:/Reserach/DL_Lab/venv/Scripts/python.exe e:/Reserach/DL_Lab/cifar_updated.py
2025-07-23 01:23:32.788568: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical 
results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-07-23 01:23:34.463461: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical 
results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
E:\Reserach\DL_Lab\venv\Lib\site-packages\keras\src\layers\convolutional\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.  
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2025-07-23 01:23:44.673539: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU 
instructions in performance-critical operations.
To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
E:\Reserach\DL_Lab\venv\Lib\site-packages\keras\src\trainers\data_adapters\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class 
should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
Epoch 1/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 197ms/step - accuracy: 0.3534 - loss: 3.0994   
Epoch 1: val_accuracy improved from -inf to 0.56960, saving model to best_cifar_model.h5
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`.
782/782 ━━━━━━━━━━━━━━━━━━━━ 173s 207ms/step - accuracy: 0.3535 - loss: 3.0989 - val_accuracy: 0.5696 - val_loss: 1.9722 - learning_rate: 
0.0010
Epoch 2/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 211ms/step - accuracy: 0.5412 - loss: 1.9782  
Epoch 2: val_accuracy improved from 0.56960 to 0.60720, saving model to best_cifar_model.h5
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`.
782/782 ━━━━━━━━━━━━━━━━━━━━ 173s 221ms/step - accuracy: 0.5412 - loss: 1.9780 - val_accuracy: 0.6072 - val_loss: 1.7275 - learning_rate: 
0.0010
Epoch 3/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 209ms/step - accuracy: 0.6014 - loss: 1.6396   
Epoch 3: val_accuracy improved from 0.60720 to 0.67290, saving model to best_cifar_model.h5
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`.
782/782 ━━━━━━━━━━━━━━━━━━━━ 200s 219ms/step - accuracy: 0.6014 - loss: 1.6395 - val_accuracy: 0.6729 - val_loss: 1.4379 - learning_rate: 
0.0010
Epoch 4/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 215ms/step - accuracy: 0.6344 - loss: 1.5212   
Epoch 4: val_accuracy did not improve from 0.67290
782/782 ━━━━━━━━━━━━━━━━━━━━ 207s 225ms/step - accuracy: 0.6344 - loss: 1.5212 - val_accuracy: 0.6726 - val_loss: 1.4055 - learning_rate: 
0.0010
Epoch 5/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 214ms/step - accuracy: 0.6540 - loss: 1.4729   
Epoch 5: val_accuracy improved from 0.67290 to 0.70190, saving model to best_cifar_model.h5
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`.
782/782 ━━━━━━━━━━━━━━━━━━━━ 202s 225ms/step - accuracy: 0.6540 - loss: 1.4729 - val_accuracy: 0.7019 - val_loss: 1.3668 - learning_rate: 
0.0010
Epoch 6/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 224ms/step - accuracy: 0.6664 - loss: 1.4397  
Epoch 6: val_accuracy improved from 0.70190 to 0.73600, saving model to best_cifar_model.h5
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`.
782/782 ━━━━━━━━━━━━━━━━━━━━ 183s 234ms/step - accuracy: 0.6664 - loss: 1.4397 - val_accuracy: 0.7360 - val_loss: 1.2650 - learning_rate: 
0.0010
Epoch 7/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 224ms/step - accuracy: 0.6804 - loss: 1.4104  
Epoch 7: val_accuracy did not improve from 0.73600
782/782 ━━━━━━━━━━━━━━━━━━━━ 182s 233ms/step - accuracy: 0.6804 - loss: 1.4104 - val_accuracy: 0.6938 - val_loss: 1.4036 - learning_rate: 
0.0010
Epoch 8/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 225ms/step - accuracy: 0.6844 - loss: 1.3975  
Epoch 8: val_accuracy did not improve from 0.73600
782/782 ━━━━━━━━━━━━━━━━━━━━ 184s 235ms/step - accuracy: 0.6844 - loss: 1.3975 - val_accuracy: 0.7176 - val_loss: 1.3292 - learning_rate: 
0.0010
Epoch 9/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 227ms/step - accuracy: 0.6901 - loss: 1.3844  
Epoch 9: val_accuracy did not improve from 0.73600
782/782 ━━━━━━━━━━━━━━━━━━━━ 185s 237ms/step - accuracy: 0.6901 - loss: 1.3844 - val_accuracy: 0.6587 - val_loss: 1.5453 - learning_rate: 
0.0010
Epoch 10/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 225ms/step - accuracy: 0.6989 - loss: 1.3751  
Epoch 10: val_accuracy did not improve from 0.73600
782/782 ━━━━━━━━━━━━━━━━━━━━ 184s 235ms/step - accuracy: 0.6989 - loss: 1.3751 - val_accuracy: 0.6749 - val_loss: 1.4877 - learning_rate: 
0.0010
Epoch 11/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 228ms/step - accuracy: 0.7022 - loss: 1.3685  
Epoch 11: val_accuracy improved from 0.73600 to 0.75600, saving model to best_cifar_model.h5
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`.
782/782 ━━━━━━━━━━━━━━━━━━━━ 186s 238ms/step - accuracy: 0.7022 - loss: 1.3685 - val_accuracy: 0.7560 - val_loss: 1.2180 - learning_rate: 
0.0010
Epoch 12/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 228ms/step - accuracy: 0.7073 - loss: 1.3484  
Epoch 12: val_accuracy did not improve from 0.75600
782/782 ━━━━━━━━━━━━━━━━━━━━ 186s 237ms/step - accuracy: 0.7073 - loss: 1.3484 - val_accuracy: 0.7176 - val_loss: 1.3615 - learning_rate: 
0.0010
Epoch 13/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 224ms/step - accuracy: 0.7085 - loss: 1.3458  
Epoch 13: val_accuracy did not improve from 0.75600
782/782 ━━━━━━━━━━━━━━━━━━━━ 183s 234ms/step - accuracy: 0.7085 - loss: 1.3458 - val_accuracy: 0.7462 - val_loss: 1.2503 - learning_rate: 
0.0010
Epoch 14/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 224ms/step - accuracy: 0.7179 - loss: 1.3282  
Epoch 14: val_accuracy did not improve from 0.75600
782/782 ━━━━━━━━━━━━━━━━━━━━ 183s 233ms/step - accuracy: 0.7179 - loss: 1.3282 - val_accuracy: 0.7280 - val_loss: 1.3007 - learning_rate: 
0.0010
Epoch 15/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 225ms/step - accuracy: 0.7189 - loss: 1.3161  
Epoch 15: val_accuracy did not improve from 0.75600
782/782 ━━━━━━━━━━━━━━━━━━━━ 184s 235ms/step - accuracy: 0.7189 - loss: 1.3161 - val_accuracy: 0.7401 - val_loss: 1.2676 - learning_rate: 
0.0010
Epoch 16/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 238ms/step - accuracy: 0.7204 - loss: 1.3184  
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.

Epoch 16: val_accuracy did not improve from 0.75600
782/782 ━━━━━━━━━━━━━━━━━━━━ 195s 249ms/step - accuracy: 0.7204 - loss: 1.3184 - val_accuracy: 0.6616 - val_loss: 1.5393 - learning_rate: 
0.0010
Epoch 17/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 238ms/step - accuracy: 0.7453 - loss: 1.2028  
Epoch 17: val_accuracy did not improve from 0.75600
782/782 ━━━━━━━━━━━━━━━━━━━━ 194s 248ms/step - accuracy: 0.7453 - loss: 1.2027 - val_accuracy: 0.7055 - val_loss: 1.2715 - learning_rate: 
5.0000e-04
Epoch 18/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 227ms/step - accuracy: 0.7530 - loss: 1.0916  
Epoch 18: val_accuracy improved from 0.75600 to 0.78440, saving model to best_cifar_model.h5
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`.
782/782 ━━━━━━━━━━━━━━━━━━━━ 185s 237ms/step - accuracy: 0.7530 - loss: 1.0916 - val_accuracy: 0.7844 - val_loss: 0.9988 - learning_rate: 
5.0000e-04
Epoch 19/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 225ms/step - accuracy: 0.7558 - loss: 1.0646  
Epoch 19: val_accuracy improved from 0.78440 to 0.79670, saving model to best_cifar_model.h5
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`.
782/782 ━━━━━━━━━━━━━━━━━━━━ 184s 235ms/step - accuracy: 0.7557 - loss: 1.0646 - val_accuracy: 0.7967 - val_loss: 0.9435 - learning_rate: 
5.0000e-04
Epoch 20/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 228ms/step - accuracy: 0.7580 - loss: 1.0505  
Epoch 20: val_accuracy did not improve from 0.79670
782/782 ━━━━━━━━━━━━━━━━━━━━ 186s 238ms/step - accuracy: 0.7580 - loss: 1.0505 - val_accuracy: 0.7747 - val_loss: 1.0111 - learning_rate: 
5.0000e-04
Epoch 21/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 228ms/step - accuracy: 0.7626 - loss: 1.0394  
Epoch 21: val_accuracy did not improve from 0.79670
782/782 ━━━━━━━━━━━━━━━━━━━━ 186s 238ms/step - accuracy: 0.7626 - loss: 1.0394 - val_accuracy: 0.7701 - val_loss: 1.0181 - learning_rate: 
5.0000e-04
Epoch 22/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 235ms/step - accuracy: 0.7628 - loss: 1.0303  
Epoch 22: val_accuracy did not improve from 0.79670
782/782 ━━━━━━━━━━━━━━━━━━━━ 192s 245ms/step - accuracy: 0.7628 - loss: 1.0303 - val_accuracy: 0.7732 - val_loss: 1.0064 - learning_rate: 
5.0000e-04
Epoch 23/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 230ms/step - accuracy: 0.7615 - loss: 1.0361  
Epoch 23: val_accuracy did not improve from 0.79670
782/782 ━━━━━━━━━━━━━━━━━━━━ 188s 240ms/step - accuracy: 0.7615 - loss: 1.0361 - val_accuracy: 0.7503 - val_loss: 1.0935 - learning_rate: 
5.0000e-04
Epoch 24/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 227ms/step - accuracy: 0.7650 - loss: 1.0342  
Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.

Epoch 24: val_accuracy did not improve from 0.79670
782/782 ━━━━━━━━━━━━━━━━━━━━ 185s 237ms/step - accuracy: 0.7650 - loss: 1.0342 - val_accuracy: 0.7569 - val_loss: 1.0791 - learning_rate: 
5.0000e-04
Epoch 25/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 229ms/step - accuracy: 0.7807 - loss: 0.9686  
Epoch 25: val_accuracy improved from 0.79670 to 0.81400, saving model to best_cifar_model.h5
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`.
782/782 ━━━━━━━━━━━━━━━━━━━━ 187s 239ms/step - accuracy: 0.7807 - loss: 0.9685 - val_accuracy: 0.8140 - val_loss: 0.8532 - learning_rate: 
2.5000e-04
Epoch 26/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 230ms/step - accuracy: 0.7847 - loss: 0.9089  
Epoch 26: val_accuracy did not improve from 0.81400
782/782 ━━━━━━━━━━━━━━━━━━━━ 187s 239ms/step - accuracy: 0.7847 - loss: 0.9089 - val_accuracy: 0.8048 - val_loss: 0.8517 - learning_rate: 
2.5000e-04
Epoch 27/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 229ms/step - accuracy: 0.7899 - loss: 0.8740  
Epoch 27: val_accuracy did not improve from 0.81400
782/782 ━━━━━━━━━━━━━━━━━━━━ 187s 239ms/step - accuracy: 0.7899 - loss: 0.8740 - val_accuracy: 0.8093 - val_loss: 0.8273 - learning_rate: 
2.5000e-04
Epoch 28/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 230ms/step - accuracy: 0.7944 - loss: 0.8642  
Epoch 28: val_accuracy improved from 0.81400 to 0.82060, saving model to best_cifar_model.h5
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`.
782/782 ━━━━━━━━━━━━━━━━━━━━ 188s 240ms/step - accuracy: 0.7944 - loss: 0.8642 - val_accuracy: 0.8206 - val_loss: 0.7707 - learning_rate: 
2.5000e-04
Epoch 29/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 230ms/step - accuracy: 0.7953 - loss: 0.8525  
Epoch 29: val_accuracy did not improve from 0.82060
782/782 ━━━━━━━━━━━━━━━━━━━━ 187s 239ms/step - accuracy: 0.7953 - loss: 0.8525 - val_accuracy: 0.8093 - val_loss: 0.8166 - learning_rate: 
2.5000e-04
Epoch 30/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 231ms/step - accuracy: 0.7951 - loss: 0.8472  
Epoch 30: val_accuracy improved from 0.82060 to 0.82490, saving model to best_cifar_model.h5
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`.
782/782 ━━━━━━━━━━━━━━━━━━━━ 189s 241ms/step - accuracy: 0.7951 - loss: 0.8472 - val_accuracy: 0.8249 - val_loss: 0.7730 - learning_rate: 
2.5000e-04
Epoch 31/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 234ms/step - accuracy: 0.7983 - loss: 0.8372  
Epoch 31: val_accuracy did not improve from 0.82490
782/782 ━━━━━━━━━━━━━━━━━━━━ 191s 244ms/step - accuracy: 0.7983 - loss: 0.8372 - val_accuracy: 0.7770 - val_loss: 0.9339 - learning_rate: 
2.5000e-04
Epoch 32/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 232ms/step - accuracy: 0.8001 - loss: 0.8284  
Epoch 32: val_accuracy did not improve from 0.82490
782/782 ━━━━━━━━━━━━━━━━━━━━ 189s 242ms/step - accuracy: 0.8001 - loss: 0.8284 - val_accuracy: 0.8030 - val_loss: 0.8323 - learning_rate: 
2.5000e-04
Epoch 33/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 231ms/step - accuracy: 0.7955 - loss: 0.8346  
Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.

Epoch 33: val_accuracy did not improve from 0.82490
782/782 ━━━━━━━━━━━━━━━━━━━━ 189s 241ms/step - accuracy: 0.7955 - loss: 0.8346 - val_accuracy: 0.7798 - val_loss: 0.9059 - learning_rate: 
2.5000e-04
Epoch 34/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 231ms/step - accuracy: 0.8003 - loss: 0.8120  
Epoch 34: val_accuracy did not improve from 0.82490
782/782 ━━━━━━━━━━━━━━━━━━━━ 188s 241ms/step - accuracy: 0.8003 - loss: 0.8120 - val_accuracy: 0.8242 - val_loss: 0.7464 - learning_rate: 
1.2500e-04
Epoch 35/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 230ms/step - accuracy: 0.8112 - loss: 0.7707  
Epoch 35: val_accuracy improved from 0.82490 to 0.82820, saving model to best_cifar_model.h5
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`.
782/782 ━━━━━━━━━━━━━━━━━━━━ 188s 240ms/step - accuracy: 0.8112 - loss: 0.7707 - val_accuracy: 0.8282 - val_loss: 0.7181 - learning_rate: 
1.2500e-04
Epoch 36/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 230ms/step - accuracy: 0.8104 - loss: 0.7607  
Epoch 36: val_accuracy improved from 0.82820 to 0.82980, saving model to best_cifar_model.h5
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`.
782/782 ━━━━━━━━━━━━━━━━━━━━ 188s 241ms/step - accuracy: 0.8104 - loss: 0.7607 - val_accuracy: 0.8298 - val_loss: 0.7122 - learning_rate: 
1.2500e-04
Epoch 37/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 232ms/step - accuracy: 0.8125 - loss: 0.7486  
Epoch 37: val_accuracy did not improve from 0.82980
782/782 ━━━━━━━━━━━━━━━━━━━━ 189s 242ms/step - accuracy: 0.8125 - loss: 0.7486 - val_accuracy: 0.8273 - val_loss: 0.7164 - learning_rate: 
1.2500e-04
Epoch 38/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 231ms/step - accuracy: 0.8137 - loss: 0.7376  
Epoch 38: val_accuracy did not improve from 0.82980
782/782 ━━━━━━━━━━━━━━━━━━━━ 189s 241ms/step - accuracy: 0.8137 - loss: 0.7376 - val_accuracy: 0.8213 - val_loss: 0.7374 - learning_rate: 
1.2500e-04
Epoch 39/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 229ms/step - accuracy: 0.8182 - loss: 0.7241  
Epoch 39: val_accuracy improved from 0.82980 to 0.83250, saving model to best_cifar_model.h5
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`.
782/782 ━━━━━━━━━━━━━━━━━━━━ 187s 240ms/step - accuracy: 0.8182 - loss: 0.7241 - val_accuracy: 0.8325 - val_loss: 0.6890 - learning_rate: 
1.2500e-04
Epoch 40/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 229ms/step - accuracy: 0.8211 - loss: 0.7121  
Epoch 40: val_accuracy did not improve from 0.83250
782/782 ━━━━━━━━━━━━━━━━━━━━ 188s 240ms/step - accuracy: 0.8211 - loss: 0.7121 - val_accuracy: 0.8302 - val_loss: 0.6996 - learning_rate: 
1.2500e-04
Epoch 41/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 231ms/step - accuracy: 0.8179 - loss: 0.7188  
Epoch 41: val_accuracy did not improve from 0.83250
782/782 ━━━━━━━━━━━━━━━━━━━━ 188s 240ms/step - accuracy: 0.8179 - loss: 0.7188 - val_accuracy: 0.8161 - val_loss: 0.7331 - learning_rate: 
1.2500e-04
Epoch 42/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 229ms/step - accuracy: 0.8211 - loss: 0.7069  
Epoch 42: val_accuracy improved from 0.83250 to 0.83480, saving model to best_cifar_model.h5
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`.
782/782 ━━━━━━━━━━━━━━━━━━━━ 187s 239ms/step - accuracy: 0.8211 - loss: 0.7069 - val_accuracy: 0.8348 - val_loss: 0.6802 - learning_rate: 
1.2500e-04
Epoch 43/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 231ms/step - accuracy: 0.8204 - loss: 0.7074  
Epoch 43: val_accuracy improved from 0.83480 to 0.83940, saving model to best_cifar_model.h5
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`.
782/782 ━━━━━━━━━━━━━━━━━━━━ 191s 244ms/step - accuracy: 0.8204 - loss: 0.7074 - val_accuracy: 0.8394 - val_loss: 0.6488 - learning_rate: 
1.2500e-04
Epoch 44/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 229ms/step - accuracy: 0.8216 - loss: 0.6990  
Epoch 44: val_accuracy did not improve from 0.83940
782/782 ━━━━━━━━━━━━━━━━━━━━ 187s 239ms/step - accuracy: 0.8216 - loss: 0.6990 - val_accuracy: 0.8327 - val_loss: 0.6808 - learning_rate: 
1.2500e-04
Epoch 45/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 231ms/step - accuracy: 0.8215 - loss: 0.7003  
Epoch 45: val_accuracy did not improve from 0.83940
782/782 ━━━━━━━━━━━━━━━━━━━━ 188s 241ms/step - accuracy: 0.8215 - loss: 0.7003 - val_accuracy: 0.8290 - val_loss: 0.6933 - learning_rate: 
1.2500e-04
Epoch 46/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 239ms/step - accuracy: 0.8193 - loss: 0.7027  
Epoch 46: val_accuracy did not improve from 0.83940
782/782 ━━━━━━━━━━━━━━━━━━━━ 195s 249ms/step - accuracy: 0.8193 - loss: 0.7027 - val_accuracy: 0.8314 - val_loss: 0.6786 - learning_rate: 
1.2500e-04
Epoch 47/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 242ms/step - accuracy: 0.8193 - loss: 0.6982  
Epoch 47: val_accuracy did not improve from 0.83940
782/782 ━━━━━━━━━━━━━━━━━━━━ 199s 254ms/step - accuracy: 0.8193 - loss: 0.6982 - val_accuracy: 0.8299 - val_loss: 0.6843 - learning_rate: 
1.2500e-04
Epoch 48/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 239ms/step - accuracy: 0.8200 - loss: 0.6867  
Epoch 48: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.

Epoch 48: val_accuracy did not improve from 0.83940
782/782 ━━━━━━━━━━━━━━━━━━━━ 195s 249ms/step - accuracy: 0.8200 - loss: 0.6867 - val_accuracy: 0.8229 - val_loss: 0.7075 - learning_rate: 
1.2500e-04
Epoch 49/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 236ms/step - accuracy: 0.8276 - loss: 0.6750  
Epoch 49: val_accuracy did not improve from 0.83940
782/782 ━━━━━━━━━━━━━━━━━━━━ 193s 246ms/step - accuracy: 0.8276 - loss: 0.6750 - val_accuracy: 0.8382 - val_loss: 0.6464 - learning_rate: 
6.2500e-05
Epoch 50/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 234ms/step - accuracy: 0.8263 - loss: 0.6680  
Epoch 50: val_accuracy did not improve from 0.83940
782/782 ━━━━━━━━━━━━━━━━━━━━ 190s 243ms/step - accuracy: 0.8263 - loss: 0.6680 - val_accuracy: 0.8345 - val_loss: 0.6639 - learning_rate: 
6.2500e-05
Epoch 51/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 231ms/step - accuracy: 0.8291 - loss: 0.6613  
Epoch 51: val_accuracy improved from 0.83940 to 0.84030, saving model to best_cifar_model.h5
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`.
782/782 ━━━━━━━━━━━━━━━━━━━━ 189s 242ms/step - accuracy: 0.8291 - loss: 0.6613 - val_accuracy: 0.8403 - val_loss: 0.6387 - learning_rate: 
6.2500e-05
Epoch 52/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 236ms/step - accuracy: 0.8317 - loss: 0.6498  
Epoch 52: val_accuracy did not improve from 0.84030
782/782 ━━━━━━━━━━━━━━━━━━━━ 192s 246ms/step - accuracy: 0.8317 - loss: 0.6498 - val_accuracy: 0.8384 - val_loss: 0.6343 - learning_rate: 
6.2500e-05
Epoch 53/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 232ms/step - accuracy: 0.8326 - loss: 0.6502   
Epoch 53: val_accuracy did not improve from 0.84030
782/782 ━━━━━━━━━━━━━━━━━━━━ 199s 242ms/step - accuracy: 0.8326 - loss: 0.6502 - val_accuracy: 0.8393 - val_loss: 0.6388 - learning_rate: 
6.2500e-05
Epoch 54/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 231ms/step - accuracy: 0.8353 - loss: 0.6357   
Epoch 54: val_accuracy did not improve from 0.84030
782/782 ━━━━━━━━━━━━━━━━━━━━ 201s 241ms/step - accuracy: 0.8353 - loss: 0.6357 - val_accuracy: 0.8373 - val_loss: 0.6447 - learning_rate: 
6.2500e-05
Epoch 55/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 233ms/step - accuracy: 0.8371 - loss: 0.6325  
Epoch 55: val_accuracy did not improve from 0.84030
782/782 ━━━━━━━━━━━━━━━━━━━━ 190s 242ms/step - accuracy: 0.8371 - loss: 0.6325 - val_accuracy: 0.8369 - val_loss: 0.6464 - learning_rate: 
6.2500e-05
Epoch 56/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 227ms/step - accuracy: 0.8350 - loss: 0.6321  
Epoch 56: val_accuracy improved from 0.84030 to 0.84330, saving model to best_cifar_model.h5
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`.
782/782 ━━━━━━━━━━━━━━━━━━━━ 185s 237ms/step - accuracy: 0.8350 - loss: 0.6321 - val_accuracy: 0.8433 - val_loss: 0.6131 - learning_rate: 
6.2500e-05
Epoch 57/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 220ms/step - accuracy: 0.8396 - loss: 0.6129  
Epoch 57: val_accuracy did not improve from 0.84330
782/782 ━━━━━━━━━━━━━━━━━━━━ 180s 230ms/step - accuracy: 0.8396 - loss: 0.6129 - val_accuracy: 0.8421 - val_loss: 0.6194 - learning_rate: 
6.2500e-05
Epoch 58/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 225ms/step - accuracy: 0.8330 - loss: 0.6301  
Epoch 58: val_accuracy did not improve from 0.84330
782/782 ━━━━━━━━━━━━━━━━━━━━ 184s 235ms/step - accuracy: 0.8330 - loss: 0.6301 - val_accuracy: 0.8418 - val_loss: 0.6217 - learning_rate: 
6.2500e-05
Epoch 59/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 221ms/step - accuracy: 0.8384 - loss: 0.6187  
Epoch 59: val_accuracy improved from 0.84330 to 0.84890, saving model to best_cifar_model.h5
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`.
782/782 ━━━━━━━━━━━━━━━━━━━━ 181s 231ms/step - accuracy: 0.8384 - loss: 0.6187 - val_accuracy: 0.8489 - val_loss: 0.5941 - learning_rate: 
6.2500e-05
Epoch 60/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 295ms/step - accuracy: 0.8349 - loss: 0.6159  
Epoch 60: val_accuracy did not improve from 0.84890
782/782 ━━━━━━━━━━━━━━━━━━━━ 238s 304ms/step - accuracy: 0.8349 - loss: 0.6159 - val_accuracy: 0.8399 - val_loss: 0.6192 - learning_rate: 
6.2500e-05
Epoch 61/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 253ms/step - accuracy: 0.8351 - loss: 0.6184  
Epoch 61: val_accuracy improved from 0.84890 to 0.85510, saving model to best_cifar_model.h5
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`.
782/782 ━━━━━━━━━━━━━━━━━━━━ 206s 263ms/step - accuracy: 0.8351 - loss: 0.6184 - val_accuracy: 0.8551 - val_loss: 0.5757 - learning_rate: 
6.2500e-05
Epoch 62/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 251ms/step - accuracy: 0.8381 - loss: 0.6077  
Epoch 62: val_accuracy did not improve from 0.85510
782/782 ━━━━━━━━━━━━━━━━━━━━ 205s 262ms/step - accuracy: 0.8381 - loss: 0.6077 - val_accuracy: 0.8458 - val_loss: 0.5973 - learning_rate: 
6.2500e-05
Epoch 63/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 251ms/step - accuracy: 0.8371 - loss: 0.6124  
Epoch 63: val_accuracy did not improve from 0.85510
782/782 ━━━━━━━━━━━━━━━━━━━━ 205s 262ms/step - accuracy: 0.8371 - loss: 0.6124 - val_accuracy: 0.8423 - val_loss: 0.6072 - learning_rate: 
6.2500e-05
Epoch 64/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 262ms/step - accuracy: 0.8379 - loss: 0.6124  
Epoch 64: val_accuracy did not improve from 0.85510
782/782 ━━━━━━━━━━━━━━━━━━━━ 216s 277ms/step - accuracy: 0.8379 - loss: 0.6123 - val_accuracy: 0.8508 - val_loss: 0.5753 - learning_rate: 
6.2500e-05
Epoch 65/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 278ms/step - accuracy: 0.8365 - loss: 0.6144  
Epoch 65: val_accuracy did not improve from 0.85510
782/782 ━━━━━━━━━━━━━━━━━━━━ 228s 291ms/step - accuracy: 0.8365 - loss: 0.6144 - val_accuracy: 0.8378 - val_loss: 0.6248 - learning_rate: 
6.2500e-05
Epoch 66/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 232ms/step - accuracy: 0.8411 - loss: 0.6011   
Epoch 66: val_accuracy did not improve from 0.85510
782/782 ━━━━━━━━━━━━━━━━━━━━ 224s 243ms/step - accuracy: 0.8411 - loss: 0.6011 - val_accuracy: 0.8435 - val_loss: 0.6076 - learning_rate: 
6.2500e-05
Epoch 67/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 226ms/step - accuracy: 0.8417 - loss: 0.6037  
Epoch 67: val_accuracy did not improve from 0.85510
782/782 ━━━━━━━━━━━━━━━━━━━━ 184s 235ms/step - accuracy: 0.8417 - loss: 0.6037 - val_accuracy: 0.8501 - val_loss: 0.5795 - learning_rate: 
6.2500e-05
Epoch 68/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 226ms/step - accuracy: 0.8417 - loss: 0.5952  
Epoch 68: val_accuracy did not improve from 0.85510
782/782 ━━━━━━━━━━━━━━━━━━━━ 184s 236ms/step - accuracy: 0.8417 - loss: 0.5952 - val_accuracy: 0.8405 - val_loss: 0.6180 - learning_rate: 
6.2500e-05
Epoch 69/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 223ms/step - accuracy: 0.8434 - loss: 0.5937  
Epoch 69: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.

Epoch 69: val_accuracy did not improve from 0.85510
782/782 ━━━━━━━━━━━━━━━━━━━━ 184s 235ms/step - accuracy: 0.8434 - loss: 0.5937 - val_accuracy: 0.8434 - val_loss: 0.6110 - learning_rate: 
6.2500e-05
Epoch 70/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 257ms/step - accuracy: 0.8441 - loss: 0.5905  
Epoch 70: val_accuracy did not improve from 0.85510
782/782 ━━━━━━━━━━━━━━━━━━━━ 209s 267ms/step - accuracy: 0.8441 - loss: 0.5905 - val_accuracy: 0.8536 - val_loss: 0.5682 - learning_rate: 
3.1250e-05
Epoch 71/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 226ms/step - accuracy: 0.8439 - loss: 0.5862  
Epoch 71: val_accuracy did not improve from 0.85510
782/782 ━━━━━━━━━━━━━━━━━━━━ 185s 236ms/step - accuracy: 0.8439 - loss: 0.5862 - val_accuracy: 0.8445 - val_loss: 0.5954 - learning_rate: 
3.1250e-05
Epoch 72/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 222ms/step - accuracy: 0.8442 - loss: 0.5833  
Epoch 72: val_accuracy did not improve from 0.85510
782/782 ━━━━━━━━━━━━━━━━━━━━ 182s 233ms/step - accuracy: 0.8442 - loss: 0.5833 - val_accuracy: 0.8456 - val_loss: 0.5912 - learning_rate: 
3.1250e-05
Epoch 73/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 216ms/step - accuracy: 0.8504 - loss: 0.5704  
Epoch 73: val_accuracy did not improve from 0.85510
782/782 ━━━━━━━━━━━━━━━━━━━━ 177s 226ms/step - accuracy: 0.8504 - loss: 0.5704 - val_accuracy: 0.8498 - val_loss: 0.5881 - learning_rate: 
3.1250e-05
Epoch 74/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 204ms/step - accuracy: 0.8479 - loss: 0.5683   
Epoch 74: val_accuracy did not improve from 0.85510
782/782 ━━━━━━━━━━━━━━━━━━━━ 192s 213ms/step - accuracy: 0.8479 - loss: 0.5683 - val_accuracy: 0.8458 - val_loss: 0.5919 - learning_rate: 
3.1250e-05
Epoch 75/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 211ms/step - accuracy: 0.8477 - loss: 0.5740  
Epoch 75: val_accuracy did not improve from 0.85510
782/782 ━━━━━━━━━━━━━━━━━━━━ 172s 220ms/step - accuracy: 0.8477 - loss: 0.5740 - val_accuracy: 0.8527 - val_loss: 0.5655 - learning_rate: 
3.1250e-05
Epoch 76/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 210ms/step - accuracy: 0.8459 - loss: 0.5746  
Epoch 76: val_accuracy did not improve from 0.85510
782/782 ━━━━━━━━━━━━━━━━━━━━ 171s 219ms/step - accuracy: 0.8459 - loss: 0.5746 - val_accuracy: 0.8509 - val_loss: 0.5696 - learning_rate: 
3.1250e-05
Epoch 77/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 209ms/step - accuracy: 0.8447 - loss: 0.5757  
Epoch 77: val_accuracy did not improve from 0.85510
782/782 ━━━━━━━━━━━━━━━━━━━━ 171s 218ms/step - accuracy: 0.8448 - loss: 0.5757 - val_accuracy: 0.8507 - val_loss: 0.5732 - learning_rate: 
3.1250e-05
Epoch 78/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 211ms/step - accuracy: 0.8487 - loss: 0.5618  
Epoch 78: val_accuracy did not improve from 0.85510
782/782 ━━━━━━━━━━━━━━━━━━━━ 172s 220ms/step - accuracy: 0.8487 - loss: 0.5618 - val_accuracy: 0.8478 - val_loss: 0.5725 - learning_rate: 
3.1250e-05
Epoch 79/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 211ms/step - accuracy: 0.8530 - loss: 0.5615  
Epoch 79: val_accuracy did not improve from 0.85510
782/782 ━━━━━━━━━━━━━━━━━━━━ 172s 220ms/step - accuracy: 0.8530 - loss: 0.5615 - val_accuracy: 0.8492 - val_loss: 0.5730 - learning_rate: 
3.1250e-05
Epoch 80/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 209ms/step - accuracy: 0.8505 - loss: 0.5627  
Epoch 80: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.

Epoch 80: val_accuracy did not improve from 0.85510
782/782 ━━━━━━━━━━━━━━━━━━━━ 171s 218ms/step - accuracy: 0.8505 - loss: 0.5627 - val_accuracy: 0.8511 - val_loss: 0.5665 - learning_rate: 
3.1250e-05
Epoch 81/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 667ms/step - accuracy: 0.8548 - loss: 0.5498  
Epoch 81: val_accuracy did not improve from 0.85510
782/782 ━━━━━━━━━━━━━━━━━━━━ 527s 674ms/step - accuracy: 0.8548 - loss: 0.5498 - val_accuracy: 0.8545 - val_loss: 0.5576 - learning_rate: 
1.5625e-05
Epoch 82/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 189ms/step - accuracy: 0.8515 - loss: 0.5470  
Epoch 82: val_accuracy did not improve from 0.85510
782/782 ━━━━━━━━━━━━━━━━━━━━ 154s 197ms/step - accuracy: 0.8515 - loss: 0.5470 - val_accuracy: 0.8510 - val_loss: 0.5663 - learning_rate: 
1.5625e-05
Epoch 83/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 199ms/step - accuracy: 0.8523 - loss: 0.5548  
Epoch 83: val_accuracy did not improve from 0.85510
782/782 ━━━━━━━━━━━━━━━━━━━━ 162s 208ms/step - accuracy: 0.8523 - loss: 0.5548 - val_accuracy: 0.8527 - val_loss: 0.5545 - learning_rate: 
1.5625e-05
Epoch 84/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 200ms/step - accuracy: 0.8493 - loss: 0.5589  
Epoch 84: val_accuracy did not improve from 0.85510
782/782 ━━━━━━━━━━━━━━━━━━━━ 163s 208ms/step - accuracy: 0.8493 - loss: 0.5589 - val_accuracy: 0.8525 - val_loss: 0.5618 - learning_rate: 
1.5625e-05
Epoch 85/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 203ms/step - accuracy: 0.8508 - loss: 0.5529  
Epoch 85: val_accuracy did not improve from 0.85510
782/782 ━━━━━━━━━━━━━━━━━━━━ 165s 211ms/step - accuracy: 0.8508 - loss: 0.5529 - val_accuracy: 0.8520 - val_loss: 0.5562 - learning_rate: 
1.5625e-05
Epoch 86/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 203ms/step - accuracy: 0.8500 - loss: 0.5554  
Epoch 86: val_accuracy did not improve from 0.85510
782/782 ━━━━━━━━━━━━━━━━━━━━ 166s 212ms/step - accuracy: 0.8500 - loss: 0.5554 - val_accuracy: 0.8542 - val_loss: 0.5510 - learning_rate: 
1.5625e-05
Epoch 87/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 206ms/step - accuracy: 0.8507 - loss: 0.5476  
Epoch 87: val_accuracy did not improve from 0.85510
782/782 ━━━━━━━━━━━━━━━━━━━━ 168s 215ms/step - accuracy: 0.8507 - loss: 0.5476 - val_accuracy: 0.8532 - val_loss: 0.5534 - learning_rate: 
1.5625e-05
Epoch 88/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 205ms/step - accuracy: 0.8555 - loss: 0.5390  
Epoch 88: val_accuracy did not improve from 0.85510
782/782 ━━━━━━━━━━━━━━━━━━━━ 167s 214ms/step - accuracy: 0.8555 - loss: 0.5390 - val_accuracy: 0.8547 - val_loss: 0.5504 - learning_rate: 
1.5625e-05
Epoch 89/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 209ms/step - accuracy: 0.8532 - loss: 0.5432  
Epoch 89: val_accuracy did not improve from 0.85510
782/782 ━━━━━━━━━━━━━━━━━━━━ 170s 217ms/step - accuracy: 0.8532 - loss: 0.5432 - val_accuracy: 0.8547 - val_loss: 0.5500 - learning_rate: 
1.5625e-05
Epoch 90/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 204ms/step - accuracy: 0.8520 - loss: 0.5464  
Epoch 90: val_accuracy did not improve from 0.85510
782/782 ━━━━━━━━━━━━━━━━━━━━ 167s 213ms/step - accuracy: 0.8520 - loss: 0.5464 - val_accuracy: 0.8546 - val_loss: 0.5534 - learning_rate: 
1.5625e-05
Epoch 91/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 204ms/step - accuracy: 0.8539 - loss: 0.5464  
Epoch 91: val_accuracy did not improve from 0.85510
782/782 ━━━━━━━━━━━━━━━━━━━━ 166s 212ms/step - accuracy: 0.8539 - loss: 0.5464 - val_accuracy: 0.8515 - val_loss: 0.5635 - learning_rate: 
1.5625e-05
Epoch 92/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 3s/step - accuracy: 0.8527 - loss: 0.5444      
Epoch 92: val_accuracy did not improve from 0.85510
782/782 ━━━━━━━━━━━━━━━━━━━━ 2240s 3s/step - accuracy: 0.8527 - loss: 0.5444 - val_accuracy: 0.8541 - val_loss: 0.5516 - learning_rate: 1.5625e-05
Epoch 93/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 178ms/step - accuracy: 0.8546 - loss: 0.5369  
Epoch 93: val_accuracy improved from 0.85510 to 0.85760, saving model to best_cifar_model.h5
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`.
782/782 ━━━━━━━━━━━━━━━━━━━━ 145s 185ms/step - accuracy: 0.8546 - loss: 0.5369 - val_accuracy: 0.8576 - val_loss: 0.5400 - learning_rate: 
1.5625e-05
Epoch 94/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 181ms/step - accuracy: 0.8555 - loss: 0.5382  
Epoch 94: val_accuracy did not improve from 0.85760
782/782 ━━━━━━━━━━━━━━━━━━━━ 148s 189ms/step - accuracy: 0.8555 - loss: 0.5382 - val_accuracy: 0.8551 - val_loss: 0.5527 - learning_rate: 
1.5625e-05
Epoch 95/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 188ms/step - accuracy: 0.8596 - loss: 0.5294  
Epoch 95: val_accuracy did not improve from 0.85760
782/782 ━━━━━━━━━━━━━━━━━━━━ 153s 196ms/step - accuracy: 0.8596 - loss: 0.5294 - val_accuracy: 0.8532 - val_loss: 0.5519 - learning_rate: 
1.5625e-05
Epoch 96/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 190ms/step - accuracy: 0.8537 - loss: 0.5407  
Epoch 96: val_accuracy did not improve from 0.85760
782/782 ━━━━━━━━━━━━━━━━━━━━ 155s 198ms/step - accuracy: 0.8537 - loss: 0.5407 - val_accuracy: 0.8546 - val_loss: 0.5435 - learning_rate: 
1.5625e-05
Epoch 97/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 194ms/step - accuracy: 0.8558 - loss: 0.5369  
Epoch 97: val_accuracy did not improve from 0.85760
782/782 ━━━━━━━━━━━━━━━━━━━━ 158s 202ms/step - accuracy: 0.8558 - loss: 0.5369 - val_accuracy: 0.8528 - val_loss: 0.5498 - learning_rate: 
1.5625e-05
Epoch 98/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 194ms/step - accuracy: 0.8537 - loss: 0.5343  
Epoch 98: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.

Epoch 98: val_accuracy did not improve from 0.85760
782/782 ━━━━━━━━━━━━━━━━━━━━ 159s 203ms/step - accuracy: 0.8537 - loss: 0.5343 - val_accuracy: 0.8547 - val_loss: 0.5422 - learning_rate: 
1.5625e-05
Epoch 99/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 200ms/step - accuracy: 0.8555 - loss: 0.5271   
Epoch 99: val_accuracy did not improve from 0.85760
782/782 ━━━━━━━━━━━━━━━━━━━━ 206s 208ms/step - accuracy: 0.8555 - loss: 0.5271 - val_accuracy: 0.8553 - val_loss: 0.5443 - learning_rate: 
7.8125e-06
Epoch 100/100
782/782 ━━━━━━━━━━━━━━━━━━━━ 0s 200ms/step - accuracy: 0.8561 - loss: 0.5279  
Epoch 100: val_accuracy did not improve from 0.85760
782/782 ━━━━━━━━━━━━━━━━━━━━ 164s 209ms/step - accuracy: 0.8561 - loss: 0.5279 - val_accuracy: 0.8545 - val_loss: 0.5423 - learning_rate: 
7.8125e-06